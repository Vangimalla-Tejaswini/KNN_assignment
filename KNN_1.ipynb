{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658cb2f4",
   "metadata": {},
   "source": [
    "#### Q1. What is the KNN algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4271215",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a simple, instance-based learning algorithm used for classification and regression tasks. It classifies or predicts a target variable by finding the majority class (classification tasks)or average value of the K nearest data points in the feature space.(regression tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c238e",
   "metadata": {},
   "source": [
    "#### Q2. How do you choose the value of K in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9d8ce",
   "metadata": {},
   "source": [
    "The value of K is typically chosen through cross-validation, where different values of K are tried and the one that gives the best performance (e.g., highest accuracy or lowest error) on validation data is selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1105ee0",
   "metadata": {},
   "source": [
    "#### Q3. What is the difference between KNN classifier and KNN regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fa269",
   "metadata": {},
   "source": [
    "KNN classifier predicts the class label of a new instance based on the majority class of its K nearest neighbors, while KNN regressor predicts the numerical value of the target variable by averaging the values of its K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb19e4",
   "metadata": {},
   "source": [
    "#### Q4. How do you measure the performance of KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482c396",
   "metadata": {},
   "source": [
    "Performance of KNN can be measured using various evaluation metrics such as accuracy, precision, recall, F1-score for classification tasks, and metrics like Mean Squared Error (MSE) or Mean Absolute Error (MAE) for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b7449",
   "metadata": {},
   "source": [
    "#### Q5. What is the curse of dimensionality in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5f8e3",
   "metadata": {},
   "source": [
    "The curse of dimensionality refers to the phenomena where in high-dimensional spaces, the distance between nearest and farthest neighbors becomes almost equal, making it difficult for KNN to discriminate between data points effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbfc58",
   "metadata": {},
   "source": [
    "#### Q6. How do you handle missing values in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8e313",
   "metadata": {},
   "source": [
    "You can handle missing values in KNN by imputing them with the mean, median, or mode of the feature, or by using techniques like KNN imputation where missing values are estimated based on the values of its neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208b7fd",
   "metadata": {},
   "source": [
    "#### Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67da5b",
   "metadata": {},
   "source": [
    "KNN classifier is better for classification problems where the target variable is categorical, while KNN regressor is better for regression problems where the target variable is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b87aed",
   "metadata": {},
   "source": [
    "#### Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ddcace",
   "metadata": {},
   "source": [
    "Strengths of KNN include simplicity and effectiveness for small to medium-sized datasets. Weaknesses include computational inefficiency and sensitivity to irrelevant features and outliers. These can be addressed by feature selection, dimensionality reduction techniques, and using efficient data structures for nearest neighbor search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2aca2",
   "metadata": {},
   "source": [
    "#### Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6569907b",
   "metadata": {},
   "source": [
    "Euclidean distance is the straight-line distance between two points in Euclidean space, while Manhattan distance is the sum of the absolute differences between the coordinates of the points. Euclidean distance is sensitive to magnitudes, while Manhattan distance is less sensitive and more suitable for high-dimensional spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa5e63",
   "metadata": {},
   "source": [
    "#### Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b25603",
   "metadata": {},
   "source": [
    "Feature scaling is important in KNN because it ensures that all features contribute equally to the distance computation. Without scaling, features with larger magnitudes may dominate the distance calculation, leading to biased results. Common scaling techniques include Min-Max scaling and Z-score normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d63ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9cb214",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
